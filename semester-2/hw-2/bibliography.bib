@misc{bib:bloom-arxiv,
  doi = {10.48550/ARXIV.2211.05100},
  
  url = {https://arxiv.org/abs/2211.05100},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {BLOOM: A 176B-Parameter Open-Access Multilingual Language Model},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}, language = {russian}
}

@misc{bib:what-to-tarin,
  doi = {10.48550/ARXIV.2210.15424},
  
  url = {https://arxiv.org/abs/2210.15424},
  
  author = {Scao, Teven Le and Wang, Thomas and Hesslow, Daniel and Saulnier, Lucile and Bekman, Stas and Bari, M Saiful and Biderman, Stella and Elsahar, Hady and Muennighoff, Niklas and Phang, Jason and Press, Ofir and Raffel, Colin and Sanh, Victor and Shen, Sheng and Sutawika, Lintang and Tae, Jaesung and Yong, Zheng Xin and Launay, Julien and Beltagy, Iz},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {What Language Model to Train if You Have One Million GPU Hours?},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}, language = {russian}
}


@online {bib:bloom-hf, hyphenation = {russian},
    title = {BigScience Large Open-science Open-access Multilingual Language Model},
    date = {2020},
    media={eresource},
    url = {https://huggingface.co/bigscience/bloom},
    urldate = {18.01.2023},
    language = {russian}
}
